---
title: "Minimal EDI package generated using EMLassemblyline and ediutilities"
author: "Joe Futrelle, Kate Morkeski"
date: "rsys.date"
output: html_notebook
---

Libraries used

```{r}
# two of the required packages are installed from GitHub
# library(remotes)
# remotes::install_github("EDIorg/EMLassemblyline")
# remotes::install_github("WHOIGit/ediutilities")

library(EMLassemblyline)
library(ediutilities)
library(here)
library(lubridate)
library(pander)
library(readr)
library(dplyr)
library(tidyr)
library(stringi)
library(stringr)

```

Read abundance data table

```{r}

# copied processing notes row from 2024abundanceforreal.csv and added as a column to metadata file

abundance_23 <- read_csv(here('2023abundanceforreal.csv'))
abundance_24 <- read_csv(here('2024abundanceforreal.csv'))

abundance_23 <- select(abundance_23, -lifeStage) # remove life stage column
abundance_24 <- abundance_24[-116,] # remove row of notes
abundance_24 <- abundance_24 |> mutate(across(6:last_col(), ~ as.numeric(.x)))
abundance_24 <- select(abundance_24, -scientificNameID, -AphiaID)

abundance_23$family <- gsub("Oxycephalus", "Oxycephalidae", abundance_23$family) # correct spelling
abundance_23$verbatimIdentification <- gsub("shrimp", "Shrimp", abundance_23$verbatimIdentification) # capitalize
abundance_23$scientificName <- gsub("shrimp", "Shrimp", abundance_23$scientificName) # capitalize

abundance_24$family <- gsub("Flat Fish Larvae", NA, abundance_24$family) # remove "Flat Fish Larvae" from entries in family column
abundance_24$family <- gsub("Antenariidae", "Antennariidae", abundance_24$family) # correct spelling
abundance_24$verbatimIdentification <- gsub("Nematoscelis", "Hansarsia", abundance_24$verbatimIdentification) # correct genus to accepted name
abundance_24$scientificName <- gsub("Nematoscelis", "Hansarsia", abundance_24$scientificName) # correct genus to accepted name
abundance_24$verbatimIdentification <- gsub("juvenile", "Juvenile", abundance_24$verbatimIdentification)
abundance_24$scientificName <- gsub(" juvenile", "", abundance_24$scientificName)
abundance_24$verbatimIdentification <- gsub("megalopa", "Megalopa", abundance_24$verbatimIdentification)
abundance_24$verbatimIdentification <- gsub("Cyclothones", "Cyclothone", abundance_24$verbatimIdentification)
abundance_24$scientificName <- gsub("Cyclothones", "Cyclothone", abundance_24$scientificName)

# put in order
abundance_23 <- abundance_23[order(abundance_23$family, abundance_23$scientificName, abundance_23$verbatimIdentification),]
abundance_24 <- abundance_24[order(abundance_24$family, abundance_24$scientificName, abundance_24$verbatimIdentification),]

unique(abundance_23$family)
unique(abundance_24$family)

unique(abundance_23$verbatimIdentification)
unique(abundance_24$verbatimIdentification)

unique(abundance_23$scientificName)
unique(abundance_24$scientificName)

abundance <- full_join(abundance_23, abundance_24, by = c("scientificName", "verbatimIdentification", "family"))

abundance <- abundance[order(abundance$family, abundance$scientificName, abundance$verbatimIdentification),]

unique(abundance$family)
unique(abundance$verbatimIdentification)
unique(abundance$scientificName)

sum(is.na(abundance$scientificNameID))

#needs_aphia <- filter(abundance, is.na(abundance$scientificNameID))

#write_csv(abundance,'nes-lter-trawl-transect-count_needs_aphia.csv', na = "NaN")
# write_csv(needs_aphia,'nes-lter-trawl-transect-count_needs_aphia.csv', na = "NaN")

aphia <- read_csv(here('nes-lter-trawl-transect-count_has_aphia.csv'))
aphia <- aphia[order(aphia$family, aphia$scientificName, aphia$verbatimIdentification),]
colnames(aphia)
colnames(aphia) <- c("family24","verbatimIdentification", "scientificName24","scientificNameID24","AphiaID24","Comments")

abundance <- left_join(abundance, aphia, by = 'verbatimIdentification')
check_id <- abundance[-(6:24)]
# for visual check of results # looks good

# populate blank rows in scientificNameID and AphiaID
abundance <-abundance |> 
  mutate(scientificNameID = case_when(is.na(scientificNameID) ~ scientificNameID24, TRUE ~ scientificNameID)) |>
  mutate(AphiaID = case_when(is.na(AphiaID) ~ AphiaID24, TRUE ~ AphiaID)) |>
  select(-family24, -scientificName24,-scientificNameID24,-AphiaID24,-Comments)

# replace na with zero in count columns 
abundance <- abundance |> mutate(across(6:last_col(), ~ replace_na(.x, 0))) |>
                          replace_na(list(family = "", scientificName = "", scientificNameID = ""))

write_csv(abundance,'nes-lter-trawl-transect-count-v2.csv', na = "NaN")

```

Read metadata 

## 2023

```{r}

meta_23 <- read_csv(here('nes-lter-trawl-transect-metadata.csv'))

#meta_23 <- read_csv(here('nes-lter-trawl-transect-metadata.csv'), col_types = c("c","n","c","D","c","n","c","n","n","n","n","c","c","c","c","c","c","c","n","n","n","c","c"))

meta_23$time_in_water <- as.character(meta_23$time_in_water)
meta_23$time_exit_water <- as.character(meta_23$time_exit_water)
meta_23$time_target_depth_start <- as.character(meta_23$time_target_depth_start)
meta_23$time_target_depth_stop <- as.character(meta_23$time_target_depth_stop)

meta_23$time_in_water <- substr(meta_23$time_in_water, 1, 5)
meta_23$time_exit_water <- substr(meta_23$time_exit_water, 1, 5) 
meta_23$time_target_depth_start <- substr(meta_23$time_target_depth_start, 1, 5)
meta_23$time_target_depth_stop <- substr(meta_23$time_target_depth_stop, 1, 5)

meta_23$processing_notes <- as.character(NA)
meta_23$jar_no_processed <- as.character(meta_23$jar_no_processed)

```
## 2024

```{r}

# provide column names for new trawl metadata
metaheaders <- c(
"cruise",
"cast",
"event",
"no_of_jars", 
"jar_no_processed",
"eventDate",
"depth_tow",
"station",
"percent_preserved",
"decimalLatitudeStart",
"decimalLongitudeStart",
"time_in_water",
"depth_bottom",
"time_target_depth_start",
"time_target_depth_stop",
"max_wire_out",
"vessel_tow_speed",
"time_exit_water",
"decimalLatitudeEnd",
"decimalLongitudeEnd",
"cod_end_fullness",
"preparations",
"processing_notes")

# Kate manually edited metadata2024fixed.csv provided by Sarah:
# removed processing_notes column from count file and added to this file
# edited preparations and processing_notes columns to remove commas
meta_24 <- read_csv(here('metadata2024fixed_KM.csv'), col_names = metaheaders)
meta_24 <- meta_24[-1,]

# define headers for columns in desired order
metaheaders <- c(
"cruise",
"cast",
"event",
"eventDate",
"station",
"depth_bottom",
"depth_tow",
"decimalLatitudeStart",
"decimalLongitudeStart",
"decimalLatitudeEnd",
"decimalLongitudeEnd",
"time_in_water",
"time_exit_water",
"time_target_depth_start",
"time_target_depth_stop",
"max_wire_out",
"vessel_tow_speed",
"cod_end_fullness",
"no_of_jars", 
"jar_no_processed",
"percent_preserved",
"preparations",
"processing_notes")
# reorder columns 
meta_24 <- meta_24[, metaheaders]

meta_24$eventDate <- mdy(meta_24$eventDate)

# 2024 metadata corrections to range:
meta_24 <- meta_24 |> mutate(depth_tow = case_when(depth_tow == "29 (18-42)" ~ "18-42",
                                      TRUE ~ depth_tow)) |>
                mutate(depth_tow = case_when(depth_tow == "103 (91-127)" ~ "91-127",
                                      TRUE ~ depth_tow))

# 2024 metadata corrections to numeric value:
meta_24 <- meta_24 |> mutate(max_wire_out = case_when(max_wire_out == "120,165,115" ~ "165",
                                      TRUE ~ max_wire_out)) |>
                mutate(max_wire_out = case_when(max_wire_out == "207->130" ~ "207",
                                      TRUE ~ max_wire_out)) |>
                mutate(vessel_tow_speed = case_when(vessel_tow_speed == "3.5-3.0-2.5-3.2-3.5-3.0" ~ "3.1", #average
                                      TRUE ~ vessel_tow_speed)) |>
                mutate(vessel_tow_speed = case_when(vessel_tow_speed == "~3.5" ~ "3.5", 
                                      TRUE ~ vessel_tow_speed)) |>
                mutate(vessel_tow_speed = case_when(vessel_tow_speed == "3.5->3" ~ "3.3", # rough average
                                      TRUE ~ vessel_tow_speed))

# # 2023 metadata corrections to numeric value:
# meta <- meta |> mutate(max_wire_out = case_when(max_wire_out == "608-928" ~ "928",
#                                       TRUE ~ max_wire_out)) |>
#                  mutate(vessel_tow_speed = case_when(vessel_tow_speed == "2-2.3" ~ "2.2",
#                                       TRUE ~ vessel_tow_speed))


meta_24 <- meta_24 |> mutate_at(c("cast",
                             "depth_bottom",
                             "decimalLatitudeStart",
                             "decimalLongitudeStart",
                             "decimalLatitudeEnd",
                             "decimalLongitudeEnd",
                             "max_wire_out",
                             "vessel_tow_speed",
                             "no_of_jars",
                             "percent_preserved"), as.numeric)

meta <- rbind(meta_23, meta_24)

write_csv(meta,'nes-lter-trawl-transect-metadata-v2.csv')

```

Generate basic summary of data table

```{r}
# Just for inspecting the summary: change all character columns to factor
DF <- names
DF[sapply(DF, is.character)] <- lapply(DF[sapply(DF, is.character)], as.factor)
pander::pander(summary(DF))

sort(unique(DF$scientificName))

```

Read the Excel metadata template and generate text templates used by
EMLassemblyline

```{r}
excel_to_template(here('trawl-transect-info-v2'), 'nes-lter-trawl-transect-v2', rights='CCBY', file_type=".md")

sheet_to_tsv('trawl-transect-info-v2.xlsx', 'ColumnHeadersCount', 'attributes_nes-lter-trawl-transect-count-v2.txt')

sheet_to_tsv('trawl-transect-info-v2.xlsx', 'ColumnHeadersMeta', 'attributes_nes-lter-trawl-transect-metadata-v2.txt')
 
sheet_to_tsv('trawl-transect-info-v2.xlsx', 'CategoricalVariables', 'catvars_nes-lter-trawl-transect-count-v2.txt')         

template_taxonomic_coverage(
  path = here(),
  data.path = here(),
  taxa.table = "nes-lter-trawl-transect-count-v2.csv",
  taxa.col = "scientificName",
  taxa.name.type = "scientific",
  taxa.authority = c(9, 3, 11),
  empty = FALSE,
  write.file = TRUE
)

```
Generate the package and insert the parent project node into the resulting EML

```{r}
# generate EML
pkg_id <- 'knb-lter-nes.34.2'

make_eml(here(),
         dataset.title='Zooplankton and micronekton abundance using an Isaacs-Kidd Midwater trawl on Northeast U.S. Shelf Long Term Ecological Research (NES-LTER) Transect cruises, ongoing since 2023',
         data.table= c('nes-lter-trawl-transect-count-v2.csv', 'nes-lter-trawl-transect-metadata-v2.csv'),
         data.table.description= c('Zooplankton and micronekton abundance', 'Net tow metadata'),
         data.table.name = c('nes-lter-trawl-transect-abundance-v2', 'nes-lter-trawl-transect-metadata-v2'),
         temporal.coverage = temporal_coverage(meta$eventDate),
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = geographic_coordinates(meta$decimalLatitudeStart, meta$decimalLongitudeStart),
         maintenance.description = "ongoing",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

project_insert(pkg_id, "parent_project_NESI-II.txt")

issues()
```

